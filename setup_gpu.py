"""
Script de diagn√≥stico e configura√ß√£o GPU/CUDA para Whisper

Verifica se GPU est√° dispon√≠vel e fornece instru√ß√µes de instala√ß√£o.
"""

import subprocess
import sys

def check_nvidia_gpu():
    """Verifica se h√° GPU NVIDIA no sistema."""
    try:
        result = subprocess.run(
            ['nvidia-smi'], 
            capture_output=True, 
            text=True, 
            check=True
        )
        print("‚úÖ GPU NVIDIA detectada:")
        print(result.stdout)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("‚ùå GPU NVIDIA n√£o detectada ou nvidia-smi n√£o instalado")
        return False

def check_cuda_pytorch():
    """Verifica se PyTorch tem suporte CUDA."""
    try:
        import torch
        print(f"\nüì¶ PyTorch vers√£o: {torch.__version__}")
        print(f"üîß CUDA dispon√≠vel: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"üéÆ GPU: {torch.cuda.get_device_name(0)}")
            print(f"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
            print(f"üî¢ CUDA version: {torch.version.cuda}")
            return True
        else:
            print("‚ö†Ô∏è  PyTorch instalado SEM suporte CUDA (CPU-only)")
            return False
    except ImportError:
        print("‚ùå PyTorch n√£o instalado")
        return False

def print_installation_guide():
    """Imprime guia de instala√ß√£o PyTorch com CUDA."""
    print("\n" + "="*80)
    print("COMO INSTALAR PYTORCH COM SUPORTE CUDA/GPU")
    print("="*80)
    
    print("\n1Ô∏è‚É£  VERIFICAR VERS√ÉO CUDA DO SISTEMA:")
    print("   Execute: nvidia-smi")
    print("   Veja a vers√£o CUDA no topo (ex: CUDA Version: 12.1)")
    
    print("\n2Ô∏è‚É£  DESINSTALAR PYTORCH ATUAL (CPU-only):")
    print("   pip uninstall torch torchvision torchaudio")
    
    print("\n3Ô∏è‚É£  INSTALAR PYTORCH COM CUDA:")
    print("   Visite: https://pytorch.org/get-started/locally/")
    print("\n   Para CUDA 11.8:")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    
    print("\n   Para CUDA 12.1:")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    
    print("\n4Ô∏è‚É£  VERIFICAR INSTALA√á√ÉO:")
    print("   python -c \"import torch; print(torch.cuda.is_available())\"")
    print("   (Deve retornar: True)")
    
    print("\n5Ô∏è‚É£  REINSTALAR WHISPER (opcional):")
    print("   pip install --upgrade --force-reinstall openai-whisper")
    
    print("\n" + "="*80)
    print("BENEF√çCIOS GPU:")
    print("="*80)
    print("‚ö° Velocidade: 10-50x mais r√°pido que CPU")
    print("üéØ Precis√£o: Mesma qualidade, processamento mais eficiente")
    print("‚è±Ô∏è  Tempo estimado: 63 min de √°udio em ~5-10 min (vs 30-60 min em CPU)")
    print("="*80 + "\n")

def main():
    print("="*80)
    print("DIAGN√ìSTICO GPU/CUDA PARA WHISPER")
    print("="*80 + "\n")
    
    has_nvidia = check_nvidia_gpu()
    has_cuda = check_cuda_pytorch()
    
    if has_nvidia and not has_cuda:
        print("\n‚ö†Ô∏è  ATEN√á√ÉO:")
        print("Voc√™ tem GPU NVIDIA, mas PyTorch est√° em modo CPU-only!")
        print_installation_guide()
    elif has_nvidia and has_cuda:
        print("\n‚úÖ SISTEMA CONFIGURADO CORRETAMENTE!")
        print("GPU/CUDA est√° pronta para uso com Whisper.")
    elif not has_nvidia:
        print("\nüí° INFO:")
        print("Nenhuma GPU NVIDIA detectada. Whisper rodar√° em CPU (mais lento).")
        print("Para melhor performance, use uma m√°quina com GPU NVIDIA.")
    
    print("\nüîç PARA USAR GPU NO WHISPER:")
    print("Adicione device='cuda' ao carregar o modelo:")
    print("model = whisper.load_model('large-v3', device='cuda')")

if __name__ == "__main__":
    main()
